{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e0e76611cbb44ad62e64b6c33ebd88195c42ce7f4e3674c65dd3e7e45acb1af1",
   "display_name": "Python 3.8.8 64-bit (windows store)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e0e76611cbb44ad62e64b6c33ebd88195c42ce7f4e3674c65dd3e7e45acb1af1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Heterogenous Modelling\n",
    "Using different kinds of distributions to model data, instead of only a single kind of distribution.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:theano.configdefaults:g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\sap98\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.tensor.blas:Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils as utl\n",
    "import datasets as d\n",
    "import models as m\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfm = tf.math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Get Toy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "data = d.gen_checkerboard_d3split(batch_size=N)\n",
    "batched = d.to_tf_dataset(data, batch_size=200)"
   ]
  },
  {
   "source": [
    "## Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of components per distribution\n",
    "K_TT = 5  # 10\n",
    "K_CP = 18  # 70\n",
    "# Number of dimensions of the data (features)\n",
    "M = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a distribution for each dimension of the data\n",
    "dists = [\n",
    "    tfd.Normal,     # dimension 1\n",
    "    tfd.Normal,     # dimension 2\n",
    "    tfd.Categorical # dimension 3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters used by the models\n",
    "params_TT = [\n",
    "    [\n",
    "        # distribution 1 (normal)\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        # distribution 2 (normal)\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        # distribution 3 (categorical)\n",
    "        np.ones((K_TT, K_TT, 3))\n",
    "    ]\n",
    "]\n",
    "\n",
    "params_CP = [\n",
    "    [\n",
    "        np.random.uniform(-4, 4, (K_CP, )),\n",
    "        np.random.uniform(0, 4, (K_CP, ))\n",
    "    ], [\n",
    "        np.random.uniform(-4, 4, (K_CP, )),\n",
    "        np.random.uniform(0, 4, (K_CP, ))\n",
    "    ], [\n",
    "        np.ones((K_CP, 3))\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modifyer used for each dimension\n",
    "# set to None for categorical\n",
    "modifiers = {\n",
    "    0: {1: tfm.softplus},\n",
    "    1: {1: tfm.softplus}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "TT = m.TensorTrainGeneral(K_TT, dists, params_TT, modifiers)\n",
    "CP = m.CPGeneral(K_CP, dists, params_CP, modifiers)"
   ]
  },
  {
   "source": [
    "## Fit models to data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs to train on\n",
    "EPOCHS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train TT general version\n",
    "losses_TT = TT.fit(batched, EPOCHS, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train TT fixed gaussian version \n",
    "losses_CP = CP.fit(batched, EPOCHS, optimizer)"
   ]
  },
  {
   "source": [
    "## Display Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Loss Plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 1, figsize=(9,6))\n",
    "ax[0].plot(losses_TT)\n",
    "ax[0].set_title(\"Heterogeneous TT\")\n",
    "ax[0].set_ylim([3.5, 6])\n",
    "ax[1].plot(losses_CP)\n",
    "ax[1].set_title(\"Heterogeneous CP\")\n",
    "ax[1].set_ylim([3.5, 6])\n",
    "f.tight_layout()\n",
    "f.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Negative Log-Likelihood pr. sample\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Density Plots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utl.plot_density_3d(CP, 3, \"Heterogeneous CP Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utl.plot_density_3d(TT, 3, \"Heterogeneous TT Decomposition\")"
   ]
  },
  {
   "source": [
    "### Sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the models\n",
    "N_samples = 1000\n",
    "TT_samples = TT.sample(N_samples)\n",
    "CP_samples = CP.sample(N_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the samples\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 0, 0], CP_samples[CP_samples[:, 2] == 0, 1], '.')\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 1, 0], CP_samples[CP_samples[:, 2] == 1, 1], '.')\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 2, 0], CP_samples[CP_samples[:, 2] == 2, 1], '.')\n",
    "ax[0].set_title('Sampling from CP model')\n",
    "\n",
    "ax[1].plot(CP_samples[CP_samples[:, 2] == 0, 0], CP_samples[CP_samples[:, 2] == 0, 1], '.')\n",
    "ax[1].plot(CP_samples[CP_samples[:, 2] == 1, 0], CP_samples[CP_samples[:, 2] == 1, 1], '.')\n",
    "ax[1].plot(CP_samples[CP_samples[:, 2] == 2, 0], CP_samples[CP_samples[:, 2] == 2, 1], '.')\n",
    "ax[1].set_title('Sampling from TT model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}