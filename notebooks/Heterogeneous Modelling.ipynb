{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd001cb84de86a5208407a6e18e6a90b135c2a22450b27d071bcb13d33d8110182d",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "01cb84de86a5208407a6e18e6a90b135c2a22450b27d071bcb13d33d8110182d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Heterogenous Modelling\n",
    "Using different kinds of distributions to model data, instead of only a single kind of distribution.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\sap98\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils as utl\n",
    "import datasets as d\n",
    "import models as m\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfm = tf.math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Get Toy Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "data = d.gen_checkerboard_d3split(batch_size=N)\n",
    "batched = d.to_tf_dataset(data, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also get the three category splits\n",
    "idx_1 = data[:, 2] == 0\n",
    "idx_2 = data[:, 2] == 1\n",
    "idx_3 = data[:, 2] == 2\n",
    "points_1 = data[idx_1, 0:2]\n",
    "points_2 = data[idx_2, 0:2]\n",
    "points_3 = data[idx_3, 0:2]"
   ]
  },
  {
   "source": [
    "## Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of components per distribution\n",
    "K_TT = 10   # 5, 10\n",
    "K_CP = 70   # 18, 70\n",
    "# Number of dimensions of the data (features)\n",
    "M = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a distribution for each dimension of the data\n",
    "dists = [\n",
    "    tfd.Normal,     # dimension 1\n",
    "    tfd.Normal,     # dimension 2\n",
    "    tfd.Categorical # dimension 3\n",
    "]\n",
    "dists_GMM = [\n",
    "    tfd.Normal,\n",
    "    tfd.Normal,\n",
    "    tfd.Normal\n",
    "]\n",
    "dists_GMM_2d = [\n",
    "    tfd.Normal,\n",
    "    tfd.Normal\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters used by the models\n",
    "params_TT = [\n",
    "    [\n",
    "        # distribution 1 (normal)\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        # distribution 2 (normal)\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        # distribution 3 (categorical)\n",
    "        np.ones((K_TT, K_TT, 3))\n",
    "    ]\n",
    "]\n",
    "\n",
    "params_CP = [\n",
    "    [\n",
    "        np.random.uniform(-4, 4, (K_CP, )),\n",
    "        np.random.uniform(0, 4, (K_CP, ))\n",
    "    ], [\n",
    "        np.random.uniform(-4, 4, (K_CP, )),\n",
    "        np.random.uniform(0, 4, (K_CP, ))\n",
    "    ], [\n",
    "        np.ones((K_CP, 3))\n",
    "    ],\n",
    "]\n",
    "\n",
    "params_GMM = [\n",
    "    [\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ]\n",
    "]\n",
    "\n",
    "params_GMM_2d = [\n",
    "    [\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ], [\n",
    "        np.random.uniform(-4, 4, (K_TT, K_TT)),\n",
    "        np.random.uniform(0, 4, (K_TT, K_TT))\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modifyer used for each dimension\n",
    "# set to None for categorical\n",
    "modifiers = {\n",
    "    0: {1: tfm.softplus},\n",
    "    1: {1: tfm.softplus}\n",
    "}\n",
    "modifiers_GMM = {\n",
    "    0: {1: tfm.softplus},\n",
    "    1: {1: tfm.softplus},\n",
    "    2: {1: tfm.softplus}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "TT = m.TensorTrainGeneral(K_TT, dists, params_TT, modifiers)\n",
    "CP = m.CPGeneral(K_CP, dists, params_CP, modifiers)\n",
    "GMM = m.TensorTrainGeneral(K_TT, dists_GMM, params_GMM, modifiers_GMM)\n",
    "\n",
    "GMM_1 = m.TensorTrainGeneral(K_TT, dists_GMM_2d, params_GMM_2d, modifiers)\n",
    "GMM_2 = m.TensorTrainGeneral(K_TT, dists_GMM_2d, params_GMM_2d, modifiers)\n",
    "GMM_3 = m.TensorTrainGeneral(K_TT, dists_GMM_2d, params_GMM_2d, modifiers)"
   ]
  },
  {
   "source": [
    "## Fit models to data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs to train on\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train TT\n",
    "losses_TT = TT.fit(batched, EPOCHS, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CP\n",
    "losses_CP = CP.fit(batched, EPOCHS, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train GMM\n",
    "losses_GMM = GMM.fit(batched, EPOCHS, optimizer)\n",
    "\n",
    "losses_GMM_1 = GMM_1.fit(d.to_tf_dataset(points_1, batch_size=200), EPOCHS, optimizer)\n",
    "losses_GMM_2 = GMM_2.fit(d.to_tf_dataset(points_2, batch_size=200), EPOCHS, optimizer)\n",
    "losses_GMM_3 = GMM_3.fit(d.to_tf_dataset(points_3, batch_size=200), EPOCHS, optimizer)"
   ]
  },
  {
   "source": [
    "## Display Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Loss Plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 1, figsize=(9,6))\n",
    "ax[0].plot(losses_TT)\n",
    "ax[0].set_title(\"Heterogeneous TT\")\n",
    "ax[1].plot(losses_CP)\n",
    "ax[1].set_title(\"Heterogeneous CP\")\n",
    "ax[2].plot(losses_GMM)\n",
    "ax[2].set_title(\"GMM\")\n",
    "f.tight_layout()\n",
    "f.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Negative Log-Likelihood pr. sample\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Density Plots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(18, 18))\n",
    "\n",
    "col = 'purple'\n",
    "mark_size = 3\n",
    "ax[0, 0].plot(points_1[:, 0], points_1[:, 1], '.', c=col, ms=mark_size)\n",
    "ax[1, 0].plot(points_2[:, 0], points_2[:, 1], '.', c=col, ms=mark_size)\n",
    "ax[2, 0].plot(points_3[:, 0], points_3[:, 1], '.', c=col, ms=mark_size)\n",
    "\n",
    "for i in range(3):\n",
    "    ax[i, 0].set_xlim((-4, 4))\n",
    "    ax[i, 0].set_ylim((-4, 4))\n",
    "    ax[i, 0].patch.set_facecolor('black')\n",
    "    ax[i, 0].set_yticklabels([])\n",
    "    ax[i, 0].set_xticklabels([])\n",
    "\n",
    "utl.plot_density_3d_paper(\n",
    "    TT, \n",
    "    ax[:, 1],\n",
    "    cmap='inferno',\n",
    "    n_points=300,\n",
    "    limit=4\n",
    ")\n",
    "utl.plot_density_3d_paper(\n",
    "    GMM, \n",
    "    ax[:, 2],\n",
    "    cmap='inferno',\n",
    "    n_points=300,\n",
    "    limit=4\n",
    ")\n",
    "\n",
    "font_clr = \"black\"\n",
    "ax[0, 0].set_title('Data', fontsize=20, color=font_clr)\n",
    "ax[0, 1].set_title('HTT', fontsize=20, color=font_clr)\n",
    "ax[0, 2].set_title('GTT', fontsize=20, color=font_clr)\n",
    "\n",
    "ax[0, 0].set_ylabel('Category 1', fontsize=20, color=font_clr)\n",
    "ax[1, 0].set_ylabel('Category 2', fontsize=20, color=font_clr)\n",
    "ax[2, 0].set_ylabel('Category 3', fontsize=20, color=font_clr)\n",
    "\n",
    "# f.patch.set_facecolor('black')\n",
    "f.tight_layout()\n",
    "plt.savefig('../figures/heterogenous_comparison_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the models\n",
    "N_samples = 1000\n",
    "TT_samples = TT.sample(N_samples)\n",
    "CP_samples = CP.sample(N_samples)\n",
    "GMM_samples = GMM.sample(N_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the samples\n",
    "f, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 0, 0], CP_samples[CP_samples[:, 2] == 0, 1], '.')\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 1, 0], CP_samples[CP_samples[:, 2] == 1, 1], '.')\n",
    "ax[0].plot(CP_samples[CP_samples[:, 2] == 2, 0], CP_samples[CP_samples[:, 2] == 2, 1], '.')\n",
    "ax[0].set_title('Sampling from CP model')\n",
    "\n",
    "ax[1].plot(TT_samples[TT_samples[:, 2] == 0, 0], TT_samples[TT_samples[:, 2] == 0, 1], '.')\n",
    "ax[1].plot(TT_samples[TT_samples[:, 2] == 1, 0], TT_samples[TT_samples[:, 2] == 1, 1], '.')\n",
    "ax[1].plot(TT_samples[TT_samples[:, 2] == 2, 0], TT_samples[TT_samples[:, 2] == 2, 1], '.')\n",
    "ax[1].set_title('Sampling from TT model')\n",
    "\n",
    "ax[2].plot(GMM_samples[np.round(GMM_samples[:, 2]) == 0, 0], GMM_samples[np.round(GMM_samples[:, 2]) == 0, 1], '.')\n",
    "ax[2].plot(GMM_samples[np.round(GMM_samples[:, 2]) == 1, 0], GMM_samples[np.round(GMM_samples[:, 2]) == 1, 1], '.')\n",
    "ax[2].plot(GMM_samples[np.round(GMM_samples[:, 2]) == 2, 0], GMM_samples[np.round(GMM_samples[:, 2]) == 2, 1], '.')\n",
    "ax[2].set_title('Sampling from GMM model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}